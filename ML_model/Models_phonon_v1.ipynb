{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2ae72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "import pickle\n",
    "import neptune as neptune\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression, VarianceThreshold\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d2b104",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the pandas dataframe with features for training model\n",
    "df = pd.read_pickle('./dataforml_automatminer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691924c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['last phdos peak'].hist(bins=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f676784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate targets and features\n",
    "y=df.iloc[:,0] #targets\n",
    "X=df.iloc[:,1:] #features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a53d181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List with model names that will be trained and evaluated\n",
    "models_names =['LinearRegression', 'Ridge', 'Lasso', 'RandomForestRegressor', \n",
    "               'GradientBoostingRegressor']#,'KernelRidge']\n",
    "\n",
    "kvals = [50, 'all'] # feature reduction parameters for linear models    \n",
    "    \n",
    "# Dict with model instances with hyperparameters for gridsearchCV to optimize and validate models\n",
    "models_dicts = {LinearRegression(n_jobs=-1):{'selector__k': kvals, # Number of features to select\n",
    "    'selector__score_func': [f_regression], # SelectKBest score functions\n",
    "    'regressor__fit_intercept': [True, False], # LinearRegression model parameters\n",
    "    'regressor__positive':[True, False], # LinearRegression model parameters\n",
    "                      },\n",
    "    Ridge():{'selector__k': kvals, # Number of features to select\n",
    "    'selector__score_func': [f_regression], # SelectKBest score functions\n",
    "    'regressor__fit_intercept': [True, False], # RidgeRegression model parameters\n",
    "    'regressor__positive':[True, False], # RidgeRegression model parameters\n",
    "    'regressor__alpha': [0.1, 1.0, 5, 10, 15], # RidgeRegression model parameters\n",
    "}, \n",
    "    Lasso(max_iter=10000): {'selector__k': kvals, # Number of features to select\n",
    "    'selector__score_func': [f_regression], # SelectKBest score functions\n",
    "    'regressor__fit_intercept': [True, False], # Lasso model parameters\n",
    "    'regressor__positive':[True, False], # Lasso model parameters\n",
    "    'regressor__alpha': [0.1, 1.0, 5, 10, 15], # Lasso model parameters\n",
    "},\n",
    "     RandomForestRegressor(n_jobs=24): {'selector__k': kvals, # Number of features to select\n",
    "    'selector__score_func': [f_regression], # SelectKBest score functions\n",
    "    'regressor__n_estimators': [500],#list(np.linspace(100,500, 3, dtype = int,endpoint=True)), # RandomForestRegressor model parameters\n",
    "    #'regressor__min_samples_leaf': list(np.linspace(2,6, 5, dtype = int, endpoint=True)), # RandomForestRegressor model param\n",
    "    #'regressor__max_depth': [5,10, 15]\n",
    "     },\n",
    "    GradientBoostingRegressor(): {'selector__k': kvals, # Number of features to select\n",
    "    'selector__score_func': [f_regression], # SelectKBest score functions\n",
    "    'regressor__n_estimators': [500],#list(np.linspace(100,500, 3, dtype = int,endpoint=True)), # GradientBoostingRegressor model parameters\n",
    "    #'regressor__learning_rate': [0.1, 0.3, 0.5, 0.7, 0.9, 1], # GradientBoostingRegressor model parameters\n",
    "    #'regressor__min_samples_leaf': list(np.linspace(1,5, 5, dtype= int, endpoint=True)), # RandomForestRegressor model param\n",
    "},\n",
    "    KernelRidge(): {'selector__k': kvals, # Number of features to select\n",
    "    'selector__score_func': [f_regression], # SelectKBest score functions\n",
    "    'regressor__kernel': [\"linear\", \"rbf\", \"poly\", \"cosine\"], # KernelRidge model parameters\n",
    "    'regressor__alpha': [0.1, 1.0, 5, 10, 15] # KernelRidge model parameters\n",
    "}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b88484c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importance_plot(gridsearchcv_obj, modelname, features, iteration):\n",
    "    feature_score=[]\n",
    "    feature_names=[]\n",
    "\n",
    "    for ind, (i, v) in enumerate(zip(gridsearchcv_obj.best_estimator_.steps[1][1].scores_, \n",
    "                    gridsearchcv_obj.best_estimator_.steps[1][1].get_support())):\n",
    "        if v == True:\n",
    "            feature_score.append(i)\n",
    "            feature_names.append(features.columns[ind].split('|')[-1])\n",
    "\n",
    "    # Create and save plot to neptune logger        \n",
    "    fig_feat = go.Figure(data=go.Bar(\n",
    "        x=feature_score,\n",
    "        y=feature_names,\n",
    "        orientation='h',\n",
    "    ))\n",
    "    fig_feat.update_layout(yaxis = dict(tickfont = dict(size=11)))\n",
    "    fig_feat.update_layout(xaxis = dict(tickfont = dict(size=11)))\n",
    "    fig_feat.update_yaxes(title_font=dict(size=22), color='black')\n",
    "    fig_feat.update_xaxes(title_font=dict(size=22), color='black')\n",
    "    fig_feat.update_xaxes(showline=True, linewidth=1, linecolor='black', mirror=True, showgrid=False)\n",
    "    fig_feat.update_yaxes(showline=True, linewidth=1, linecolor='black', mirror=True, showgrid=False)\n",
    "    fig_feat.update_xaxes(ticks=\"inside\", tickwidth=1, tickcolor='black', ticklen=5)\n",
    "    fig_feat.update_yaxes(ticks=\"inside\", tickwidth=1, tickcolor='black', ticklen=5)\n",
    "    fig_feat.update_layout(template='simple_white')\n",
    "    fig_feat.update_layout(width=1000, height =1000)\n",
    "    fig_feat.update_layout(title_text='Feature scores', title_x=0.5)\n",
    "    fig_feat.write_html(\"{}/{}_features_{}.html\".format(modelname, modelname, iteration),include_mathjax = 'cdn')\n",
    "    \n",
    "    return fig_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd437a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_plot(errors_test,errors_train, modelname):\n",
    "    fig_val = go.Figure()\n",
    "\n",
    "    fig_val.add_trace(go.Violin(x0=name,\n",
    "                            y=error_data_test.values,\n",
    "                            legendgroup='Test',name='Test',\n",
    "                            side='positive', #scalegroup='Train',\n",
    "                            line_color='blue', box_visible=True)\n",
    "                 )\n",
    "    fig_val.add_trace(go.Violin(x0=name,\n",
    "                            y=error_data_train.values,\n",
    "                            legendgroup='Train',name='Train',\n",
    "                            side='negative', #scalegroup='Test',\n",
    "                            line_color='orange', box_visible=True)\n",
    "                 )\n",
    "    fig_val.update_traces(meanline_visible=True)\n",
    "    fig_val.update_layout(violingap=0, violinmode='overlay')\n",
    "    fig_val.update_traces(marker_opacity=0.75)\n",
    "    fig_val.update_layout(yaxis = dict(tickfont = dict(size=11)))\n",
    "    fig_val.update_layout(xaxis = dict(tickfont = dict(size=11)))\n",
    "    fig_val.update_yaxes(title_font=dict(size=22), color='black')\n",
    "    fig_val.update_xaxes(title_font=dict(size=22), color='black')\n",
    "    fig_val.update_layout(width=1000, height =1000)\n",
    "    fig_val.update_xaxes(showline=True, linewidth=1, linecolor='black', mirror=True, showgrid=False)\n",
    "    fig_val.update_yaxes(showline=True, linewidth=1, linecolor='black', mirror=True, showgrid=False)\n",
    "    fig_val.update_xaxes(ticks=\"inside\", tickwidth=1, tickcolor='black', ticklen=5)\n",
    "    fig_val.update_yaxes(ticks=\"inside\", tickwidth=1, tickcolor='black', ticklen=5)\n",
    "    fig_val.update_layout(yaxis = dict(tickfont = dict(size=18)))\n",
    "    fig_val.update_layout(yaxis_title=\"Validation Absolute error\")\n",
    "    fig_val.update_layout(yaxis = dict(tickfont = dict(size=18)))\n",
    "    fig_val.update_layout(xaxis = dict(tickfont = dict(size=18)))\n",
    "    fig_val.update_layout(template='simple_white')\n",
    "    fig_val.update_layout(yaxis_zeroline=False)\n",
    "    fig_val.write_html(\"{}/{}_validation.html\".format(modelname,modelname),include_mathjax = 'cdn')\n",
    "\n",
    "    \n",
    "    return fig_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd605a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shap_plot(model, X_train, iteration, modelname):\n",
    "    feature_score=[]\n",
    "    feature_names=[]\n",
    "    for ind, (i, v) in enumerate(zip(model.steps[1][1].scores_, \n",
    "                        model.steps[1][1].get_support())):\n",
    "            if v == True:\n",
    "                feature_score.append(i)\n",
    "                feature_names.append(X_train.columns[ind])\n",
    "\n",
    "    std_scaler = StandardScaler() \n",
    "\n",
    "    std_scaler.fit(X_train.filter(feature_names)) \n",
    "\n",
    "    X_train_scaled = std_scaler.transform(X_train.filter(feature_names))\n",
    "    if modelname == 'RandomForestRegressor' or modelname =='GradientBoostingRegressor':\n",
    "        explainer = shap.TreeExplainer(model.steps[2][1], X_train_scaled)\n",
    "        shap_values = explainer.shap_values(X_train_scaled, check_additivity=False)\n",
    "    elif modelname =='KernelRidge':\n",
    "        explainer = shap.KernelExplainer(model.steps[2][1].predict, X_train_scaled)\n",
    "        shap_values = explainer.shap_values(X_train_scaled)\n",
    "    else:\n",
    "        explainer = shap.LinearExplainer(model.steps[2][1], X_train_scaled)\n",
    "        shap_values = explainer.shap_values(X_train_scaled)\n",
    "    \n",
    "    fig = shap.summary_plot(shap_values, features=X_train_scaled, feature_names=X_train.filter(feature_names).columns, show=False)\n",
    "    plt.savefig('{}/{}_{}.svg'.format(modelname,modelname,iteration))\n",
    "    plt.close()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a41619a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(index=models_names)\n",
    "trained_models={}\n",
    "for name, (model, param) in zip(models_names, models_dicts.items()):\n",
    "    print(name + ' model training')\n",
    "    os.mkdir(name)\n",
    "    #scorer = {'RMSE':'neg_root_mean_squared_error', 'r2': 'r2'}\n",
    "    #scorer = {'MAE':'neg_mean_absolute_error'}\n",
    "\n",
    "    cv_outer = KFold(n_splits=5, shuffle=True, random_state=18012019)\n",
    "    # enumerate splits\n",
    "    outer_test_rmse = []\n",
    "    outer_train_rmse =[]\n",
    "\n",
    "    outer_test_r2 = []\n",
    "    outer_train_r2 =[]\n",
    "    test_errors=[]\n",
    "    train_errors=[]\n",
    "    iteration=1\n",
    "    for train_ix, test_ix in cv_outer.split(X):\n",
    "        # split data\n",
    "        X_train, X_test = X.iloc[train_ix, :], X.iloc[test_ix, :]\n",
    "        y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "        # configure the cross-validation procedure\n",
    "        cv_inner = KFold(n_splits=2, shuffle=True, random_state=18012019)\n",
    "        # define the model\n",
    "        if name == 'RandomForestRegressor' or name =='GradientBoostingRegressor': #can be removed later\n",
    "            \n",
    "            pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('selector', SelectKBest()),\n",
    "            ('regressor', model)\n",
    "            ])\n",
    "        else:\n",
    "            pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('selector', SelectKBest()),\n",
    "            ('regressor', model)\n",
    "            ])\n",
    "\n",
    "        # define search space\n",
    "        hyperparameters = param\n",
    "        # define search\n",
    "        search = GridSearchCV(pipeline, param_grid=hyperparameters, scoring='neg_mean_absolute_error',\n",
    "                                                                             cv=cv_inner, \n",
    "                              refit=True, return_train_score=True, n_jobs=24)\n",
    "        # execute search\n",
    "        result = search.fit(X_train, y_train)\n",
    "        # get the best performing model fit on the whole training set\n",
    "        best_model = result.best_estimator_\n",
    "\n",
    "        y_train_pred = best_model.predict(X_train)\n",
    "        # evaluate model on the hold out dataset\n",
    "        yhat = best_model.predict(X_test)\n",
    "        # evaluate the model\n",
    "        rmse_test = mean_squared_error(y_test, yhat, squared=False)\n",
    "        rmse_train = mean_squared_error(y_train, y_train_pred, squared=False)\n",
    "\n",
    "        r2_test = r2_score(y_test, yhat)\n",
    "        r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "        test_error = abs(y_test - yhat)\n",
    "        train_error = abs(y_train - y_train_pred)\n",
    "\n",
    "        # store the result\n",
    "        outer_test_rmse.append(rmse_test)\n",
    "        outer_train_rmse.append(rmse_train)\n",
    "\n",
    "        outer_test_r2.append(r2_test)\n",
    "        outer_train_r2.append(r2_train)\n",
    "\n",
    "        test_errors.append(test_error)\n",
    "        train_errors.append(train_error)\n",
    "        \n",
    "        filename = '{}/{}_bestmodel_{}.pkl'.format(name, name, iteration)\n",
    "        pickle.dump(best_model, open(filename, 'wb'))\n",
    "        \n",
    "        get_shap_plot(modelname=name,X_train=X_train,model=best_model, iteration=iteration)\n",
    "        \n",
    "        fig_feat = get_feature_importance_plot(gridsearchcv_obj=search, modelname=name, features=X_train, \n",
    "                                               iteration=iteration)\n",
    "        \n",
    "        print('>acc=%.3f, est=%.3f, cfg=%s' % (rmse_test, result.best_score_, result.best_params_))\n",
    "        # summarize the estimated performance of the model\n",
    "        print('Accuracy: %.3f (%.3f)' % (np.mean(outer_test_rmse), np.std(outer_test_rmse)))\n",
    "\n",
    "        \n",
    "        iteration+=1\n",
    "\n",
    "    error_data_test = pd.concat(test_errors)\n",
    "    error_data_train = pd.concat(train_errors)\n",
    "    \n",
    "\n",
    "    \n",
    "    fig_val = get_train_test_plot(errors_test=error_data_test, errors_train=error_data_train, modelname=name)\n",
    "\n",
    "    #store trained model in dict\n",
    "    trained_models.update({name+'_bestmodel': best_model, name+'_gridsearch':search})\n",
    "\n",
    "    df.loc[name,'mae_train'] = np.mean(error_data_train.values)\n",
    "    df.loc[name,'mae_test'] = np.mean(error_data_test.values)\n",
    "    df.loc[name,'std_mae_train'] = np.std(error_data_train.values)\n",
    "    df.loc[name,'std_mae_test'] = np.std(error_data_test.values)\n",
    "    df.loc[name, 'max_mae_error_train'] = np.max(error_data_train.values)\n",
    "    df.loc[name, 'max_mae_error_test'] = np.max(error_data_test.values)\n",
    "    df.loc[name, 'min_mae_error_train'] = np.min(error_data_train.values)\n",
    "    df.loc[name, 'min_mae_error_test'] = np.min(error_data_test.values)\n",
    "    \n",
    "    df.loc[name,'mean_train_rmse'] = np.mean(outer_train_rmse)\n",
    "    df.loc[name,'mean_test_rmse'] = np.mean(outer_test_rmse)\n",
    "    df.loc[name,'mean_train_r2'] = np.mean(outer_train_r2)\n",
    "    df.loc[name,'mean_test_r2'] = np.mean(outer_test_r2)\n",
    "    df.loc[name,'std_train_rmse'] = np.std(outer_train_rmse)\n",
    "    df.loc[name,'std_test_rmse'] = np.std(outer_test_rmse)\n",
    "    df.loc[name,'std_train_r2'] = np.std(outer_train_r2)\n",
    "    df.loc[name,'std_test_r2'] = np.std(outer_train_r2)\n",
    "    \n",
    "    print(name + ' done')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5091ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51613fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('summary_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b63152e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load saved models\n",
    "filename = '{}/{}_bestmodel_5.pkl'.format(models_names[0],models_names[0])\n",
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935e7745",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
