{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "641a96cd",
   "metadata": {},
   "source": [
    "## Load the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f936245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "from collections import namedtuple\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from matbench.data_ops import mean_absolute_percentage_error\n",
    "from ml_utilities import (grid_search, get_feature_importance_plot,\n",
    "                          get_shap_plot, get_train_test_plot,\n",
    "                          get_actual_predict_plot, get_metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f5d0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the pandas dataframe with targets and features for training model\n",
    "df = pd.read_pickle('./dataforml_automatminer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73349a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe with compositions for each mpid\n",
    "df_comp = pd.read_csv('mpids.csv', sep=',', index_col='metadata.material_id') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c323cee",
   "metadata": {},
   "source": [
    "**<font color='red'>Important note</font>:** Check the `n_jobs` parameter in the model_dict below. Adjust this as per your system configuration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b06b2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List with model name that will be trained and evaluated\n",
    "models_names =['RandomForestRegressor']\n",
    "\n",
    "# Dict with model hypterparameter\n",
    "models_dicts = {\n",
    "     RandomForestRegressor(n_jobs=30): {\n",
    "         'selector__n_features_to_select': [50, 100, 180], # Number of features to select\n",
    "        'regressor__n_estimators': [500],\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382f58b0",
   "metadata": {},
   "source": [
    "## The code block below will change the inputs to model training based on user selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f922e276",
   "metadata": {},
   "source": [
    "**<font color='red'>Important note</font>:** \n",
    "The user first needs to select either one of the button below to reproduce the results of the associated model presented in paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b9747e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code block to select model training input data \n",
    "heading = widgets.HTML('<h3>Please select the model you want to train and evaluate before procceding</h3>')\n",
    "include_button = widgets.Button(description='Including LOBSTER features', \n",
    "                                layout=widgets.Layout(width='300px', height='50px'),\n",
    "                               style={'font_weight': 'bold','font_size': '16px', 'border_radius': '300px'})\n",
    "\n",
    "\n",
    "exclude_button = widgets.Button(description='Excluding LOBSTER features',\n",
    "                               layout=widgets.Layout(width='300px', height='50px'),\n",
    "                               style={'font_weight': 'bold', 'font_size': '16px','border_radius': '300px'})\n",
    "\n",
    "parent = os.getcwd() # get the directory of script\n",
    "\n",
    "\n",
    "# Define the button click event handlers\n",
    "def include_button_clicked(b):\n",
    "    '''\n",
    "    This callback function includes the ICOHP features for model training and changes the output directory\n",
    "    to store the results\n",
    "    '''\n",
    "    global y, X\n",
    "    os.chdir(parent)\n",
    "    isExist = os.path.exists('inc_icohp')\n",
    "    if not isExist:\n",
    "        os.mkdir('inc_icohp')\n",
    "        os.chdir('inc_icohp')\n",
    "    else:\n",
    "        os.chdir('inc_icohp')\n",
    "        \n",
    "    y=df.iloc[:,0] #targets\n",
    "    X=df.iloc[:,1:] #features\n",
    "    print(\"LOBSTER features will be included in the model evaluation, results will be stored in the 'inc_icohp' directory\")\n",
    "    print(\"Great! Now you have the necessary data for model training and evaluation. Run the consequent code blocks\")\n",
    "    print(\"\")\n",
    "def exclude_button_clicked(b):\n",
    "    '''\n",
    "    This callback function excludes the ICOHP features for model training and changes the output directory\n",
    "    to store the results\n",
    "    '''\n",
    "    global y, X\n",
    "    os.chdir(parent)\n",
    "    isExist = os.path.exists('exc_icohp')\n",
    "    if not isExist:\n",
    "        os.mkdir('exc_icohp')\n",
    "        os.chdir('exc_icohp')\n",
    "    else:\n",
    "        os.chdir('exc_icohp')\n",
    "    \n",
    "    y=df.iloc[:,0] #targets\n",
    "    X=df.iloc[:,1:-18] #features\n",
    "    print(\"LOBSTER features will be excluded in the model evaluation, results will be stored in the 'exc_icohp' directory\")\n",
    "    print(\"Great! Now you have the necessary data for model training and evaluation. Run the consequent code blocks\")\n",
    "    print(\"\")\n",
    "# Attach the event handlers\n",
    "include_button.on_click(include_button_clicked)\n",
    "exclude_button.on_click(exclude_button_clicked)\n",
    "\n",
    "# Display the widgets\n",
    "display(heading)\n",
    "display(include_button)\n",
    "display(exclude_button)\n",
    "warning_text = \"\"\"Please ensure you selected either of options presented above.\n",
    "You will encounter error ahead as inputs necessary for model will not be instantiated if \n",
    "you don\\'t select either of the options\n",
    "\"\"\"\n",
    "display(HTML('<div class=\"alert-warning\">{}<h3></h3></div>'.format(warning_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7735cb5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define convinience named tuples to store raw metric data of nested cv runs\n",
    "abs_errors = namedtuple(\"abs_errors\", \"train test\")\n",
    "rmse_scores = namedtuple(\"rmse_scores\", \"train test\")\n",
    "r2_scores = namedtuple(\"r2_scores\", \"train test\")\n",
    "mape_scores = namedtuple(\"mape_scores\", \"train test\")\n",
    "\n",
    "print('RandomForestRegressor model training and evaluation initiated with 5 Fold Nested CV', file=sys.stderr)\n",
    "\n",
    "for name, (model, param) in zip(models_names, models_dicts.items()):\n",
    "    isExist = os.path.exists(name)\n",
    "    if not isExist:\n",
    "        os.mkdir(name)\n",
    "\n",
    "    abs_errors = namedtuple(\"abs_errors\", \"train test\")\n",
    "    rmse_scores = namedtuple(\"rmse_scores\", \"train test\")\n",
    "    r2_scores = namedtuple(\"r2_scores\", \"train test\")\n",
    "    mape_scores = namedtuple(\"mape_scores\", \"train test\")\n",
    "\n",
    "    cv_outer = KFold(n_splits=5, shuffle=True, random_state=18012019)\n",
    "\n",
    "    #store outfold metrics\n",
    "    test_rmse = []\n",
    "    train_rmse =[]\n",
    "    test_r2 = []\n",
    "    train_r2 =[]\n",
    "    test_errors=[]\n",
    "    test_labels=[]\n",
    "    train_errors=[]\n",
    "    y_actual=[]\n",
    "    y_predict=[]\n",
    "    mape_train=[]\n",
    "    mape_test=[]\n",
    "    iteration=1\n",
    "    # enumerate splits\n",
    "    for train_ix, test_ix in cv_outer.split(X):\n",
    "        print('Fold:', iteration, file=sys.stderr)\n",
    "        # split data\n",
    "        X_train, X_test = X.iloc[train_ix, :].values, X.iloc[test_ix, :].values\n",
    "        y_train, y_test = y.iloc[train_ix].values, y.iloc[test_ix].values\n",
    "        \n",
    "        #get the best model and gridsearch cv object\n",
    "        best_model, search = grid_search(model, param, X_train, y_train)\n",
    "        \n",
    "        # get train set predictions of best model\n",
    "        y_hat_train  = best_model.predict(X_train)\n",
    "        \n",
    "        # evaluate model on the hold out test dataset\n",
    "        y_hat_test = best_model.predict(X_test)\n",
    "        \n",
    "        # evaluate the model performace metrics on train and test sets\n",
    "        rmse_test = mean_squared_error(y_test, y_hat_test, squared=False)\n",
    "        rmse_train = mean_squared_error(y_train, y_hat_train, squared=False)\n",
    "\n",
    "        r2_test = r2_score(y_test, y_hat_test)\n",
    "        r2_train = r2_score(y_train, y_hat_train)\n",
    "\n",
    "        test_error = abs(y_test - y_hat_test)\n",
    "        train_error = abs(y_train - y_hat_train)\n",
    "\n",
    "        # store the result of each folds\n",
    "        test_rmse.append(rmse_test)\n",
    "        train_rmse.append(rmse_train)\n",
    "\n",
    "        test_r2.append(r2_test)\n",
    "        train_r2.append(r2_train)\n",
    "\n",
    "        test_errors.append(test_error)\n",
    "        test_labels.append(y.iloc[test_ix].index)\n",
    "        train_errors.append(train_error)\n",
    "\n",
    "        mape_train.append(mean_absolute_percentage_error(y_pred=y_hat_train, y_true=y_train))\n",
    "        mape_test.append(mean_absolute_percentage_error(y_pred=y_hat_test, y_true=y_test))\n",
    "        \n",
    "        y_actual.append(y_test)\n",
    "        y_predict.append(y_hat_test)\n",
    "\n",
    "        \n",
    "        # pickle the trained models  \n",
    "        filename = '{}/{}_bestmodel_{}.pkl'.format(name, name, iteration)\n",
    "        pickle.dump(best_model, open(filename, 'wb'))\n",
    "        \n",
    "        print('Best parameters={}'.format(search.best_params_), file=sys.stderr)\n",
    "        print('MAE  >test={}, >train={}'.format(np.mean(test_error), np.mean(train_error)), file=sys.stderr)\n",
    "        print('RMSE >test={}, >train={}'.format(rmse_test, rmse_train), file=sys.stderr)\n",
    "\n",
    "        #save feature importance plot with scores from feature selection algorithm\n",
    "        get_feature_importance_plot(gridsearchcv_obj=search, modelname=name, features=X.iloc[train_ix, :], \n",
    "                                               iteration=iteration)\n",
    "        \n",
    "        #save shapley values plot for each fold\n",
    "        get_shap_plot(modelname=name,X_train=X.iloc[train_ix, :],model=search, iteration=iteration)\n",
    "        \n",
    "        print('', file=sys.stderr)\n",
    "\n",
    "        iteration+=1\n",
    "\n",
    "    # store test and train absolute errors as violin+box plot\n",
    "    get_train_test_plot(test_errors=test_errors, train_errors=train_errors, \n",
    "                                  labels=test_labels,modelname=name)\n",
    "    \n",
    "    # populate the defined named tuples with raw data of model performace\n",
    "    train_test_errors = abs_errors(train_errors, test_errors)\n",
    "    train_test_rmse = rmse_scores(train_rmse, test_rmse)\n",
    "    train_test_r2 = r2_scores(train_r2, test_r2)\n",
    "    train_test_mape = mape_scores(mape_train, mape_test)\n",
    "\n",
    "    # pass the named tuple to obtain summarized model performace metrics pandas dataframe\n",
    "    stats_df = get_metrics_df(abs_errors=train_test_errors, rmse_scores=train_test_rmse,\n",
    "                       r2_scores=train_test_r2, mape_scores=train_test_mape, model=name)\n",
    "\n",
    "    # save the summary stats as csv\n",
    "    #stats_df.to_csv('summary_results.csv')\n",
    "    \n",
    "    df_predictions = pd.DataFrame(index=list(np.concatenate(test_labels)),\n",
    "                                columns=['Composition','lastphdospeak_actual','lastphdospeak_predicted'])\n",
    "    \n",
    "    for row, col in df_predictions.iterrows():\n",
    "        df_predictions.loc[row,'Composition'] = df_comp.loc[row,'metadata.formula']\n",
    "                                  \n",
    "    df_predictions['lastphdospeak_actual'] = np.concatenate(y_actual)\n",
    "    df_predictions['lastphdospeak_predicted'] = np.concatenate(y_predict)\n",
    "    \n",
    "    # get actual and model predict scatter plot\n",
    "    get_actual_predict_plot(df_predictions=df_predictions,modelname=name)\n",
    "    \n",
    "    # save the prediction data as csv\n",
    "    #df_predictions.to_csv('predictions_data.csv')\n",
    "                                  \n",
    "    \n",
    "    os.chdir('..')\n",
    "    \n",
    "    print(name + 'model evaluation Finished',file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29388184",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
